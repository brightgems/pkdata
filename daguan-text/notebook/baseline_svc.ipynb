{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 达观长文本分类Baseline 模型\n",
    "## 使用新的PANDAS api 加快读取大文本文件\n",
    "使用iterator迭代器读取pandas\n",
    "```\n",
    "reader = pd.read_csv(f, sep=',', iterator=True)\n",
    "reader.get_chunk(chunkSize)\n",
    "```\n",
    "\n",
    "\n",
    "## 基准模型\n",
    "使用SVC对词袋统计TFIDF值进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration is stopped.\n",
      "锘縤d         102277\n",
      "article     102277\n",
      "word_seg    102277\n",
      "class       102277\n",
      "dtype: int64\n",
      "Iteration is stopped.\n",
      "锘縤d         102277\n",
      "article     102277\n",
      "word_seg    102277\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "def gen_csv_feather(path,path_new):\n",
    "\n",
    "    f = open(path)\n",
    "\n",
    "    reader = pd.read_csv(f, sep=',', iterator=True)\n",
    "\n",
    "    loop = True\n",
    "\n",
    "    chunkSize = 10000\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    while loop:\n",
    "\n",
    "        try:\n",
    "\n",
    "            chunk = reader.get_chunk(chunkSize)\n",
    "\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        except StopIteration:\n",
    "\n",
    "            loop = False\n",
    "\n",
    "            print(\"Iteration is stopped.\")\n",
    "\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "    print(df.count())\n",
    "\n",
    "    df.to_pickle(path_new)\n",
    "    \n",
    "%time gen_csv_feather(\"../data/train_set.csv\",\"../data/train_set.pkl\")\n",
    "\n",
    "%time gen_csv_feather(\"../data/test_set.csv\",\"../data/test_set.pkl\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "column = \"word_seg\"\n",
    "train = pd.read_pickle('../data/train_set.pkl')\n",
    "test = pd.read_pickle('../data/test_set.pkl')\n",
    "train.columns = ['id','article','word_seg','class']\n",
    "test.columns = ['id','article','word_seg']\n",
    "train, validate = train_test_split(train, test_size=0.2)\n",
    "test_id = test[\"id\"].copy()\n",
    "vec = TfidfVectorizer(ngram_range=(1,2),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1)\n",
    "trn_term_doc = vec.fit_transform(train[column])\n",
    "test_term_doc = vec.transform(test[column])\n",
    "fid0=open('baseline.csv','w')\n",
    "\n",
    "y=(train[\"class\"]-1).astype(int)\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(trn_term_doc,y)\n",
    "preds = lin_clf.predict(test_term_doc)\n",
    "i=0\n",
    "fid0.write(\"id,class\"+\"\\n\")\n",
    "for item in preds:\n",
    "    fid0.write(str(i)+\",\"+str(item+1)+\"\\n\")\n",
    "    i=i+1\n",
    "fid0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.789744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_validate = (validate[\"class\"]-1).astype(int)\n",
    "trn_term_docccctrn_term_docc = vec.transform(validate[column])\n",
    "test_term_doc = vec.transform(validate[column])\n",
    "preds = lin_clf.predict(test_term_doc)\n",
    "\n",
    "accu = accuracy_score(preds, y_validate)\n",
    "print('准确率:%f'%accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>word_seg</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7368 1252069 365865 755561 1044285 129532 1053...</td>\n",
       "      <td>816903 597526 520477 1179558 1033823 758724 63...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>581131 165432 7368 957317 1197553 570900 33659...</td>\n",
       "      <td>90540 816903 441039 816903 569138 816903 10343...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7368 87936 40494 490286 856005 641588 145611 1...</td>\n",
       "      <td>816903 1012629 957974 1033823 328210 947200 65...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>299237 760651 299237 887082 159592 556634 7489...</td>\n",
       "      <td>563568 1239563 680125 780219 782805 1033823 19...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7368 7368 7368 865510 7368 396966 995243 37685...</td>\n",
       "      <td>816903 816903 816903 139132 816903 312320 1103...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            article  \\\n",
       "0   0  7368 1252069 365865 755561 1044285 129532 1053...   \n",
       "1   1  581131 165432 7368 957317 1197553 570900 33659...   \n",
       "2   2  7368 87936 40494 490286 856005 641588 145611 1...   \n",
       "3   3  299237 760651 299237 887082 159592 556634 7489...   \n",
       "4   4  7368 7368 7368 865510 7368 396966 995243 37685...   \n",
       "\n",
       "                                            word_seg  class  \n",
       "0  816903 597526 520477 1179558 1033823 758724 63...     14  \n",
       "1  90540 816903 441039 816903 569138 816903 10343...      3  \n",
       "2  816903 1012629 957974 1033823 328210 947200 65...     12  \n",
       "3  563568 1239563 680125 780219 782805 1033823 19...     13  \n",
       "4  816903 816903 816903 139132 816903 312320 1103...     12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,class\n",
      "0,1\n",
      "1,4\n",
      "2,13\n",
      "3,4\n",
      "4,15\n",
      "5,1\n",
      "6,15\n",
      "7,19\n",
      "8,3\n"
     ]
    }
   ],
   "source": [
    "!head baseline.csv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
