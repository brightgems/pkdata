{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using dataset that contains the information about individuals from various countries. Our target is to predict whether a person makes <=50k or >50k annually on basis of the other information available. Dataset consists of 32561 observations and 14 features describing individuals.\n",
    "\n",
    "Here is the link to the dataset: http://archive.ics.uci.edu/ml/datasets/Adult.\n",
    "\n",
    "Go through the dataset to have a proper intuition about predictor variables and so that you could understand the code below properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Parameters of light GBM\n",
    "- task : default value = train ; options = train , prediction ; Specifies the task we wish to perform which is either train or prediction.\n",
    "- application: default=regression, type=enum, options= options :\n",
    "    - regression : perform regression task\n",
    "    - binary : Binary classification\n",
    "    - multiclass: Multiclass Classification\n",
    "    - lambdarank : lambdarank application\n",
    "- data: type=string; training data , LightGBM will train from this data\n",
    "- num_iterations: number of boosting iterations to be performed ; default=100; type=int\n",
    "- num_leaves : number of leaves in one tree ; default = 31 ; type =int\n",
    "- device : default= cpu ; options = gpu,cpu. Device on which we want to train our model. Choose GPU for faster training.\n",
    "- max_depth: Specify the max depth to which tree will grow. This parameter is used to deal with overfitting.\n",
    "- min_data_in_leaf: Min number of data in one leaf.\n",
    "- feature_fraction: default=1 ; specifies the fraction of features to be taken for each iteration\n",
    "- bagging_fraction: default=1 ; specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting.\n",
    "- min_gain_to_split: default=.1 ; min gain to perform splitting\n",
    "- max_bin : max number of bins to bucket the feature values.\n",
    "- min_data_in_bin : min number of data in one bin\n",
    "- num_threads: default=OpenMP_default, type=int ;Number of threads for Light GBM.\n",
    "- label : type=string ; specify the label column\n",
    "- categorical_feature : type=string ; specify the categorical features we want to use for training our model\n",
    "- num_class: default=1 ; type=int ; used only for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital_Status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_Status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  Income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing standard libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas import Series, DataFrame \n",
    "\n",
    "#import lightgbm and xgboost \n",
    "import lightgbm as lgb \n",
    "import xgboost as xgb \n",
    "\n",
    "#loading our training dataset 'adult.csv' with name 'data' using pandas \n",
    "data=pd.read_csv('../data/raw/adult/adult.data',header=None) \n",
    "\n",
    "#Assigning names to the columns \n",
    "data.columns=['age','workclass','fnlwgt','education','education-num','marital_Status','occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','Income'] \n",
    "\n",
    "#glimpse of the dataset \n",
    "data.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Label Encoding our target variable \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "l=LabelEncoder() \n",
    "l.fit(data.Income) \n",
    "\n",
    "print(l.classes_)\n",
    "data.Income=Series(l.transform(data.Income))  #label encoding our target variable \n",
    "data.Income.value_counts() \n",
    "OneHotEncoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#One Hot Encoding of the Categorical features \n",
    "one_hot_workclass=pd.get_dummies(data.workclass) \n",
    "one_hot_education=pd.get_dummies(data.education) \n",
    "one_hot_marital_Status=pd.get_dummies(data.marital_Status) \n",
    "one_hot_occupation=pd.get_dummies(data.occupation)\n",
    "one_hot_relationship=pd.get_dummies(data.relationship) \n",
    "one_hot_race=pd.get_dummies(data.race) \n",
    "one_hot_sex=pd.get_dummies(data.sex) \n",
    "one_hot_native_country=pd.get_dummies(data.native_country) \n",
    "\n",
    "#removing categorical features \n",
    "data.drop(['workclass','education','marital_Status','occupation','relationship','race','sex','native_country'],axis=1,inplace=True) \n",
    "\n",
    " \n",
    "\n",
    "#Merging one hot encoded features with our dataset 'data' \n",
    "data=pd.concat([data,one_hot_workclass,one_hot_education,one_hot_marital_Status,one_hot_occupation,one_hot_relationship,one_hot_race,one_hot_sex,one_hot_native_country],axis=1) \n",
    "\n",
    "#removing dulpicate columns \n",
    "_, i = np.unique(data.columns, return_index=True) \n",
    "data=data.iloc[:, i] \n",
    "\n",
    "#Here our target variable is 'Income' with values as 1 or 0.  \n",
    "#Separating our data into features dataset x and our target dataset y \n",
    "x=data.drop('Income',axis=1) \n",
    "y=data.Income \n",
    "\n",
    "\n",
    "\n",
    "#Imputing missing values in our target variable \n",
    "y.fillna(y.mode()[0],inplace=True) \n",
    "\n",
    "#Now splitting our dataset into test and train \n",
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying xgboost\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The data is stored in a DMatrix object \n",
    "#label is used to define our outcome variable\n",
    "dtrain=xgb.DMatrix(x_train,label=y_train)\n",
    "dtest=xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting parameters for xgboost\n",
    "parameters={'max_depth':7, 'eta':1, 'silent':1,'objective':'binary:logistic','eval_metric':'auc','learning_rate':.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73 s ± 57.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#training our model \n",
    "num_round=50\n",
    "from datetime import datetime \n",
    "\n",
    "%time xg=xgb.train(parameters,dtrain,num_round) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95747328,  0.30730107,  0.18299842, ...,  0.95786685,\n",
       "        0.46510884,  0.05661203], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now predicting our model on test set \n",
    "ypred=xg.predict(dtest) \n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting probabilities into 1 or 0  \n",
    "for i in range(0,9769): \n",
    "    if ypred[i]>=.5:       # setting threshold to .5 \n",
    "       ypred[i]=1 \n",
    "    else: \n",
    "       ypred[i]=0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86446923943085274"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating accuracy of our model \n",
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_xgb = accuracy_score(y_test,ypred) \n",
    "accuracy_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgb.Dataset(x_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting parameters for lightgbm\n",
    "param = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.05,'max_bin':200}\n",
    "param['metric'] = ['auc', 'binary_logloss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Here we have set max_depth in xgb and LightGBM to 7 to have a fair comparison between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 ms ± 37.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#training our model using light gbm\n",
    "num_round=50\n",
    "\n",
    "%timeit lgbm=lgb.train(param,train_data,num_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95909121,  0.31404598,  0.18614527,  0.13907408,  0.37017331])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting on test set\n",
    "ypred2=lgbm.predict(x_test)\n",
    "ypred2[0:5]  # showing first 5 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting probabilities into 0 or 1\n",
    "for i in range(0,9769):\n",
    "    if ypred2[i]>=.5:       # setting threshold to .5\n",
    "       ypred2[i]=1\n",
    "    else:  \n",
    "       ypred2[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm: 0.863957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    7384\n",
       "1    2385\n",
       "Name: Income, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "accuracy_lgbm = accuracy_score(ypred2,y_test)\n",
    "print('lgbm: %f' % accuracy_lgbm)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77721670289435363"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating roc_auc_score for xgboost\n",
    "auc_xgb =  roc_auc_score(y_test,ypred)\n",
    "auc_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating roc_auc_score for light gbm. \n",
    "auc_lgbm = roc_auc_score(y_test,ypred2)\n",
    "comparison_dict = {'accuracy score':(accuracy_lgbm,accuracy_xgb),'auc score':(auc_lgbm,auc_xgb)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>auc score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.863957</td>\n",
       "      <td>0.776027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.864469</td>\n",
       "      <td>0.777217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy score  auc score\n",
       "LightGBM        0.863957   0.776027\n",
       "xgboost         0.864469   0.777217"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe ‘comparison_df’ for comparing the performance of Lightgbm and xgb. \n",
    "comparison_df = DataFrame(comparison_dict) \n",
    "comparison_df.index= ['LightGBM','xgboost'] \n",
    "comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
