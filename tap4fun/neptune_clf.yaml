project: brightgems/tap4fun

name: tap4fun-clf
tags: [solution-1, dev]

metric:
  channel: 'ROC_AUC'
  goal: maximize

exclude:
  - output
  - notebooks
  - dask-tutorial
  - dask-worker-space
  - holoviews-contrib
  - hv-demo
  - neptune-examples
  - torch-demo
  - workdir
  - tmp
  - data
  - src
  - old
  - open-solution-home-credit
  - neptune.log
  - offline_job.log
  - .git
  - .github
  - .idea
  - .ipynb_checkpoints

parameters:
  is_regression_problem: 0
# Data
  train_filepath:                 ./data/tap_fun_train.parquet
  test_filepath:                  ./data/tap_fun_test.parquet
  variable_filepath:          ./data/tap4fun.xlsx
  sample_submission_filepath:     ./data/sub_sample.csv
  experiment_directory:           ./workdir
  

# Kaggle
  kaggle_api: 1
  kaggle_message: 'solution-1'

# Data preparation
  n_cv_splits: 5
  validation_size: 0.2
  stratified_cv: True
  shuffle: 1

# Execution
  clean_experiment_directory_before_training: 0
  num_workers: -1
  verbose: 1

# Preprocessing
  fill_missing: True
  fill_value: 0

# Light GBM
  lgbm_random_search_runs: 0
  lgbm__device: cpu # gpu cpu
  lgbm__boosting_type: gbdt
  lgbm__objective: binary
  lgbm__metric: auc
  lgbm__num_tree_per_iteration : 10
  lgbm__number_boosting_rounds: 500
  lgbm__early_stopping_rounds: 50
  lgbm__learning_rate: 0.1
  lgbm__max_bin: 300
  lgbm__max_depth: 11
  lgbm__num_leaves: 100
  lgbm__min_child_samples: 600
  lgbm__subsample: 1.0
  lgbm__subsample_freq: 1
  lgbm__colsample_bytree: 0.1
  lgbm__min_gain_to_split: 0.5
  lgbm__reg_lambda: 50.0
  lgbm__reg_alpha: 0.0
  lgbm__scale_pos_weight: 1

# XGBoost
  xgb_random_search_runs: 0
  xgb__booster: gbtree
  xgb__tree_method: hist # gpu_hist  # auto  hist
  xgb__objective: binary:logistic
  xgb__eval_metric: auc
  xgb__nrounds: 10000
  xgb__early_stopping_rounds: 100
  xgb__eta: 0.001
  xgb__max_leaves: 40
  xgb__max_depth: 16
  xgb__max_bin: 255
  xgb__subsample: 0.5
  xgb__colsample_bytree: 0.5
  xgb__colsample_bylevel: 1
  xgb__min_child_weight: 4
  xgb__lambda: 0.001
  xgb__alpha: 0.001
  xgb__scale_pos_weight: 1

# Random forest
  rf_random_search_runs: 0
  rf__n_estimators: 15
  max_depth: 9
  rf__criterion: gini # gini|entropy
  rf__warm_start: True
  rf__max_features: 0.2
  rf__min_samples_split: 10
  rf__min_samples_leaf: 1
  rf__class_weight: 
    False:  1
    True:   3

# Logistic regression
  lr_random_search_runs: 0
  lr__penalty: l1
  lr__tol: 0.00001
  lr__C: 1
  lr__fit_intercept: 1
  lr__class_weight:
    False:  1
    True:   3  
  lr__solver: liblinear
  lr__max_iter: 10000

# SVC
  svc_random_search_runs: 0
  svc__kernel: rbf
  svc__C: 1
  svc__degree: 5
  svc__gamma: auto
  svc__coef0: 0.0
  svc__probability: True
  svc__tol: 0.00001
  svc__max_iter: -1

# Postprocessing
  aggregation_method: rank_mean