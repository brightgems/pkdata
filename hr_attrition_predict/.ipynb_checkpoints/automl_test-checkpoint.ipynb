{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to auto_ml! We're about to go through and make sense of your data using machine learning, and give you a production-ready pipeline to get predictions with.\n",
      "\n",
      "If you have any issues, or new feature ideas, let us know at http://auto.ml\n",
      "You are running on version 2.9.10\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'warm_start': True, 'learning_rate': 0.1, 'presort': False}\n",
      "Running basic data cleaning\n",
      "Fitting DataFrameVectorizer\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'warm_start': True, 'learning_rate': 0.1, 'presort': False}\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to fit the pipeline for the model GradientBoostingRegressor to predict MEDV\n",
      "Started at:\n",
      "2018-03-30 23:41:17\n",
      "[1] random_holdout_set_from_training_data's score is: -8.601\n",
      "[2] random_holdout_set_from_training_data's score is: -8.021\n",
      "[3] random_holdout_set_from_training_data's score is: -7.466\n",
      "[4] random_holdout_set_from_training_data's score is: -7.002\n",
      "[5] random_holdout_set_from_training_data's score is: -6.583\n",
      "[6] random_holdout_set_from_training_data's score is: -6.055\n",
      "[7] random_holdout_set_from_training_data's score is: -5.722\n",
      "[8] random_holdout_set_from_training_data's score is: -5.374\n",
      "[9] random_holdout_set_from_training_data's score is: -5.087\n",
      "[10] random_holdout_set_from_training_data's score is: -4.866\n",
      "[11] random_holdout_set_from_training_data's score is: -4.646\n",
      "[12] random_holdout_set_from_training_data's score is: -4.502\n",
      "[13] random_holdout_set_from_training_data's score is: -4.289\n",
      "[14] random_holdout_set_from_training_data's score is: -4.167\n",
      "[15] random_holdout_set_from_training_data's score is: -4.057\n",
      "[16] random_holdout_set_from_training_data's score is: -3.925\n",
      "[17] random_holdout_set_from_training_data's score is: -3.866\n",
      "[18] random_holdout_set_from_training_data's score is: -3.766\n",
      "[19] random_holdout_set_from_training_data's score is: -3.665\n",
      "[20] random_holdout_set_from_training_data's score is: -3.602\n",
      "[21] random_holdout_set_from_training_data's score is: -3.529\n",
      "[22] random_holdout_set_from_training_data's score is: -3.493\n",
      "[23] random_holdout_set_from_training_data's score is: -3.421\n",
      "[24] random_holdout_set_from_training_data's score is: -3.377\n",
      "[25] random_holdout_set_from_training_data's score is: -3.362\n",
      "[26] random_holdout_set_from_training_data's score is: -3.338\n",
      "[27] random_holdout_set_from_training_data's score is: -3.308\n",
      "[28] random_holdout_set_from_training_data's score is: -3.292\n",
      "[29] random_holdout_set_from_training_data's score is: -3.275\n",
      "[30] random_holdout_set_from_training_data's score is: -3.237\n",
      "[31] random_holdout_set_from_training_data's score is: -3.216\n",
      "[32] random_holdout_set_from_training_data's score is: -3.196\n",
      "[33] random_holdout_set_from_training_data's score is: -3.188\n",
      "[34] random_holdout_set_from_training_data's score is: -3.184\n",
      "[35] random_holdout_set_from_training_data's score is: -3.168\n",
      "[36] random_holdout_set_from_training_data's score is: -3.166\n",
      "[37] random_holdout_set_from_training_data's score is: -3.136\n",
      "[38] random_holdout_set_from_training_data's score is: -3.132\n",
      "[39] random_holdout_set_from_training_data's score is: -3.121\n",
      "[40] random_holdout_set_from_training_data's score is: -3.131\n",
      "[41] random_holdout_set_from_training_data's score is: -3.136\n",
      "[42] random_holdout_set_from_training_data's score is: -3.117\n",
      "[43] random_holdout_set_from_training_data's score is: -3.118\n",
      "[44] random_holdout_set_from_training_data's score is: -3.109\n",
      "[45] random_holdout_set_from_training_data's score is: -3.089\n",
      "[46] random_holdout_set_from_training_data's score is: -3.09\n",
      "[47] random_holdout_set_from_training_data's score is: -3.093\n",
      "[48] random_holdout_set_from_training_data's score is: -3.09\n",
      "[49] random_holdout_set_from_training_data's score is: -3.073\n",
      "[50] random_holdout_set_from_training_data's score is: -3.067\n",
      "[52] random_holdout_set_from_training_data's score is: -3.052\n",
      "[54] random_holdout_set_from_training_data's score is: -3.038\n",
      "[56] random_holdout_set_from_training_data's score is: -3.03\n",
      "[58] random_holdout_set_from_training_data's score is: -3.026\n",
      "[60] random_holdout_set_from_training_data's score is: -3.022\n",
      "[62] random_holdout_set_from_training_data's score is: -3.015\n",
      "[64] random_holdout_set_from_training_data's score is: -3.013\n",
      "[66] random_holdout_set_from_training_data's score is: -3.011\n",
      "[68] random_holdout_set_from_training_data's score is: -3.017\n",
      "[70] random_holdout_set_from_training_data's score is: -3.015\n",
      "[72] random_holdout_set_from_training_data's score is: -3.012\n",
      "[74] random_holdout_set_from_training_data's score is: -3.015\n",
      "[76] random_holdout_set_from_training_data's score is: -3.01\n",
      "[78] random_holdout_set_from_training_data's score is: -3.004\n",
      "[80] random_holdout_set_from_training_data's score is: -3.013\n",
      "[82] random_holdout_set_from_training_data's score is: -3.029\n",
      "[84] random_holdout_set_from_training_data's score is: -3.023\n",
      "[86] random_holdout_set_from_training_data's score is: -3.023\n",
      "[88] random_holdout_set_from_training_data's score is: -3.026\n",
      "[90] random_holdout_set_from_training_data's score is: -3.026\n",
      "[92] random_holdout_set_from_training_data's score is: -3.028\n",
      "[94] random_holdout_set_from_training_data's score is: -3.029\n",
      "[96] random_holdout_set_from_training_data's score is: -3.033\n",
      "[98] random_holdout_set_from_training_data's score is: -3.032\n",
      "[100] random_holdout_set_from_training_data's score is: -3.033\n",
      "[103] random_holdout_set_from_training_data's score is: -3.053\n",
      "[106] random_holdout_set_from_training_data's score is: -3.058\n",
      "[109] random_holdout_set_from_training_data's score is: -3.062\n",
      "[112] random_holdout_set_from_training_data's score is: -3.06\n",
      "[115] random_holdout_set_from_training_data's score is: -3.059\n",
      "[118] random_holdout_set_from_training_data's score is: -3.059\n",
      "[121] random_holdout_set_from_training_data's score is: -3.077\n",
      "[124] random_holdout_set_from_training_data's score is: -3.095\n",
      "[127] random_holdout_set_from_training_data's score is: -3.098\n",
      "The number of estimators that were the best for this training dataset: 78\n",
      "The best score on the holdout set: -3.0038563974\n",
      "Finished training the pipeline!\n",
      "Total training time:\n",
      "0:00:02\n",
      "\n",
      "\n",
      "Here are the results from our GradientBoostingRegressor\n",
      "predicting MEDV\n",
      "Calculating feature responses, for advanced analytics.\n",
      "The printed list will only contain at most the top 100 features.\n",
      "+----+----------------+--------------+----------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "|    | Feature Name   |   Importance |    Delta |   FR_Decrementing |   FR_Incrementing |   FRD_abs |   FRI_abs |   FRD_MAD |   FRI_MAD |\n",
      "|----+----------------+--------------+----------+-------------------+-------------------+-----------+-----------+-----------+-----------|\n",
      "| 57 | PTRATIO=21.1   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 22 | PTRATIO=14.9   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 24 | PTRATIO=17.3   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 26 | PTRATIO=19.6   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 27 | PTRATIO=20.2   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 56 | PTRATIO=20.1   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 29 | PTRATIO=19.2   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 30 | PTRATIO=20.9   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 20 | PTRATIO=18.7   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 31 | PTRATIO=21.2   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 35 | PTRATIO=15.3   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 36 | PTRATIO=15.5   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 38 | PTRATIO=16.6   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 41 | PTRATIO=16.8   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 43 | PTRATIO=17.9   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 44 | PTRATIO=17.6   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 45 | PTRATIO=17.0   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 32 | PTRATIO=22.0   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 19 | PTRATIO=18.2   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 47 | PTRATIO=18.9   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 17 | PTRATIO=16.1   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  1 | ZN             |       0.0000 |  11.5619 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 16 | PTRATIO=15.1   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 55 | PTRATIO=18.8   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 15 | PTRATIO=14.8   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 54 | PTRATIO=18.5   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 53 | PTRATIO=19.0   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 13 | PTRATIO=12.6   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 11 | CHAS=0.0       |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 52 | PTRATIO=19.7   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 49 | PTRATIO=18.0   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 50 | PTRATIO=18.3   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 18 | PTRATIO=15.6   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 51 | PTRATIO=19.1   |       0.0000 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 12 | CHAS=1.0       |       0.0003 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 37 | PTRATIO=15.9   |       0.0011 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 33 | PTRATIO=13.6   |       0.0014 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 25 | PTRATIO=17.8   |       0.0018 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 39 | PTRATIO=16.0   |       0.0020 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 23 | PTRATIO=16.9   |       0.0022 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 40 | PTRATIO=16.4   |       0.0031 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 42 | PTRATIO=17.4   |       0.0049 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 21 | PTRATIO=14.7   |       0.0058 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 48 | PTRATIO=18.4   |       0.0076 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 14 | PTRATIO=13.0   |       0.0076 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 34 | PTRATIO=15.2   |       0.0146 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "| 46 | PTRATIO=18.6   |       0.0157 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  7 | RAD            |       0.0193 |   4.2895 |           -0.3313 |            0.0760 |    0.3326 |    0.0854 |    0.3827 |    0.0000 |\n",
      "| 28 | PTRATIO=21.0   |       0.0249 | nan      |          nan      |          nan      |  nan      |  nan      |  nan      |  nan      |\n",
      "|  2 | INDUS          |       0.0374 |   3.4430 |            0.1432 |           -0.0275 |    0.1660 |    0.1684 |    0.0000 |    0.0000 |\n",
      "|  3 | NOX            |       0.0488 |   0.0588 |            0.2499 |           -0.2877 |    0.2843 |    0.4385 |    0.0000 |    0.0918 |\n",
      "|  0 | CRIM           |       0.0703 |   4.4291 |           -0.4293 |            0.6488 |    0.6818 |    1.1695 |    0.5786 |    0.5474 |\n",
      "|  8 | TAX            |       0.0791 |  82.9834 |            0.9837 |           -0.4326 |    1.0292 |    0.4355 |    0.2527 |    0.1948 |\n",
      "|  5 | AGE            |       0.0899 |  13.9801 |            0.0389 |           -0.0794 |    0.2966 |    0.2273 |    0.1213 |    0.1467 |\n",
      "|  9 | B              |       0.0964 |  45.7266 |           -0.4078 |            0.0645 |    0.5270 |    0.2404 |    0.1999 |    0.0809 |\n",
      "|  6 | DIS            |       0.1107 |   1.0643 |            3.2547 |           -0.0779 |    3.3840 |    0.5697 |    0.6507 |    0.1982 |\n",
      "| 10 | LSTAT          |       0.1636 |   3.5508 |            1.8801 |           -1.8070 |    1.8906 |    1.8202 |    1.7705 |    1.5852 |\n",
      "|  4 | RM             |       0.1916 |   0.3543 |           -1.0649 |            1.5039 |    1.1379 |    1.7428 |    0.3351 |    0.8007 |\n",
      "+----+----------------+--------------+----------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "\n",
      "\n",
      "*******\n",
      "Legend:\n",
      "Importance = Feature Importance\n",
      "     Explanation: A weighted measure of how much of the variance the model is able to explain is due to this column\n",
      "FR_delta = Feature Response Delta Amount\n",
      "     Explanation: Amount this column was incremented or decremented by to calculate the feature reponses\n",
      "FR_Decrementing = Feature Response From Decrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to subtracting one FR_delta amount from every value in this column\n",
      "FR_Incrementing = Feature Response From Incrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to adding one FR_delta amount to every value in this column\n",
      "FRD_MAD = Feature Response From Decrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if decrementing this feature provokes strong changes that are both positive and negative\n",
      "FRI_MAD = Feature Response From Incrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if incrementing this feature provokes strong changes that are both positive and negative\n",
      "FRD_abs = Feature Response From Decrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to subtracting one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "FRI_abs = Feature Response From Incrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to adding one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "*******\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "\n",
      "***********************************************\n",
      "Advanced scoring metrics for the trained regression model on this particular dataset:\n",
      "\n",
      "Here is the overall RMSE for these predictions:\n",
      "2.6564523628\n",
      "\n",
      "Here is the average of the predictions:\n",
      "21.277201273733557\n",
      "\n",
      "Here is the average actual value on this validation set:\n",
      "21.488235294117654\n",
      "\n",
      "Here is the median prediction:\n",
      "20.5430878643\n",
      "\n",
      "Here is the median actual value:\n",
      "20.15\n",
      "\n",
      "Here is the mean absolute error:\n",
      "2.02176370307\n",
      "\n",
      "Here is the median absolute error (robust to outliers):\n",
      "1.63417379066\n",
      "\n",
      "Here is the explained variance:\n",
      "0.904379625653\n",
      "\n",
      "Here is the R-squared value:\n",
      "0.903772329045\n",
      "Count of positive differences (prediction > actual):\n",
      "50\n",
      "Count of negative differences:\n",
      "52\n",
      "Average positive difference:\n",
      "1.846944276341709\n",
      "Average negative difference:\n",
      "-2.189859305697364\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.6564523627988872"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from auto_ml import Predictor\n",
    "from auto_ml.utils import get_boston_dataset\n",
    "\n",
    "df_train, df_test = get_boston_dataset()\n",
    "\n",
    "column_descriptions = {\n",
    "    'MEDV': 'output'\n",
    "    , 'CHAS': 'categorical','PTRATIO':'categorical'\n",
    "}\n",
    "\n",
    "ml_predictor = Predictor(type_of_estimator='regressor', column_descriptions=column_descriptions)\n",
    "\n",
    "ml_predictor.train(df_train)\n",
    "\n",
    "ml_predictor.score(df_test, df_test.MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 17,\n",
       " 19,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 33,\n",
       " 35,\n",
       " 36,\n",
       " 39,\n",
       " 45,\n",
       " 47,\n",
       " 48,\n",
       " 50,\n",
       " 55,\n",
       " 56,\n",
       " 61,\n",
       " 63,\n",
       " 64,\n",
       " 69,\n",
       " 71,\n",
       " 72,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 86,\n",
       " 89,\n",
       " 93,\n",
       " 94,\n",
       " 96,\n",
       " 98,\n",
       " 100,\n",
       " 101,\n",
       " 103,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 110,\n",
       " 111,\n",
       " 113,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 122,\n",
       " 124,\n",
       " 129,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 140,\n",
       " 143,\n",
       " 144,\n",
       " 147,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 157,\n",
       " 160,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 170,\n",
       " 171,\n",
       " 174,\n",
       " 180,\n",
       " 181,\n",
       " 183,\n",
       " 186,\n",
       " 188,\n",
       " 193,\n",
       " 196,\n",
       " 198,\n",
       " 199,\n",
       " 202,\n",
       " 203,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 212,\n",
       " 216,\n",
       " 217,\n",
       " 220,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 231,\n",
       " 234,\n",
       " 237,\n",
       " 238,\n",
       " 240,\n",
       " 242,\n",
       " 243,\n",
       " 245,\n",
       " 246,\n",
       " 249,\n",
       " 250,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 262,\n",
       " 263,\n",
       " 268,\n",
       " 270,\n",
       " 271,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 285,\n",
       " 287,\n",
       " 288,\n",
       " 291,\n",
       " 296,\n",
       " 298,\n",
       " 300,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 308,\n",
       " 309,\n",
       " 312,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 318,\n",
       " 322,\n",
       " 323,\n",
       " 326,\n",
       " 327,\n",
       " 330,\n",
       " 331,\n",
       " 334,\n",
       " 337,\n",
       " 339,\n",
       " 343,\n",
       " 345,\n",
       " 346,\n",
       " 350,\n",
       " 353,\n",
       " 357,\n",
       " 359,\n",
       " 360,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 367,\n",
       " 369,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 384,\n",
       " 387,\n",
       " 390,\n",
       " 397,\n",
       " 401,\n",
       " 402,\n",
       " 403]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "list(np.flatnonzero(df_train.RM_Group == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fitting a single feature transformation pipeline that will be shared by all of our categorical estimators for the sake of space efficiency when saving the model\n",
      "Now using the model training_params that you passed in:\n",
      "{}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{}\n",
      "Running basic data cleaning\n",
      "Performing feature scaling\n",
      "Fitting DataFrameVectorizer\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "index not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-48ff9dc90977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# ml_predictor.train(df_train, model_names=['XGBRegressor'] )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mml_predictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_categorical_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'XGBRegressor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_column\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'RM_Group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Score the model on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\envs\\tensorflow\\lib\\site-packages\\auto_ml\\predictor.py\u001b[0m in \u001b[0;36mtrain_categorical_ensemble\u001b[1;34m(self, data, categorical_column, default_category, min_category_size, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m             \u001b[0mcategory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_df_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m             \u001b[0mrelevant_transformed_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_df_transformed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m             \u001b[0mrelevant_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx_val\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python27\\envs\\tensorflow\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: index not found"
     ]
    }
   ],
   "source": [
    "from auto_ml import Predictor\n",
    "from auto_ml.utils import get_boston_dataset\n",
    "from auto_ml.utils_models import load_ml_model\n",
    "import pandas as pd\n",
    "# Load data\n",
    "df_train, df_test = get_boston_dataset()\n",
    "df_train = df_train.assign(RM_Group = lambda o: o.RM>6.3)\n",
    "df_test = df_test.assign(RM_Group = lambda o: o.RM>6.3)\n",
    "# df_train['RM_Group'] =pd.Categorical(df_train['RM_Group'])\n",
    "# df_test['RM_Group'] =pd.Categorical(df_test['RM_Group'])\n",
    "# Tell auto_ml which column is 'output'\n",
    "# Also note columns that aren't purely numerical\n",
    "# Examples include ['nlp', 'date', 'categorical', 'ignore']\n",
    "column_descriptions = {\n",
    "  'MEDV': 'output'\n",
    "}\n",
    "\n",
    "ml_predictor = Predictor(type_of_estimator='regressor', column_descriptions=column_descriptions)\n",
    "\n",
    "# ml_predictor.train(df_train, model_names=['XGBRegressor'] )\n",
    "ml_predictor.train_categorical_ensemble(df_train,model_names=['XGBRegressor'], categorical_column='RM_Group')\n",
    "\n",
    "# Score the model on test data\n",
    "test_score = ml_predictor.score(df_test, df_test.MEDV)\n",
    "\n",
    "# auto_ml is specifically tuned for running in production\n",
    "# It can get predictions on an individual row (passed in as a dictionary)\n",
    "# A single prediction like this takes ~1 millisecond\n",
    "# Here we will demonstrate saving the trained model, and loading it again\n",
    "file_name = ml_predictor.save()\n",
    "\n",
    "trained_model = load_ml_model(file_name)\n",
    "\n",
    "# .predict and .predict_proba take in either:\n",
    "# A pandas DataFrame\n",
    "# A list of dictionaries\n",
    "# A single dictionary (optimized for speed in production evironments)\n",
    "predictions = trained_model.predict(df_test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
